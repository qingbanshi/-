# 4.4 关于梯度

## 4.4.1 梯度法



**注意**:使用梯度法时,常常使用损失函数,为了获得一个较为完美的连续函数

使用梯度时,要注意因鞍点造成的"学习高原"现象,注意极小值与最小值之间的差异

梯度算法(其中n表示更新量(学习率))

![image-20200615154054392](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200615154054392.png)

*!--可否根据黑塞矩阵正定性直接求极值?*

![image-20200617083523919](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200617083523919.png)

# 4.5 一次实验

具体见 04-一次基于mini_batch的双层神经网络实现

**tips**:

1. 注意激活函数的实现
2. 注意偏置需根据节点数进行更新